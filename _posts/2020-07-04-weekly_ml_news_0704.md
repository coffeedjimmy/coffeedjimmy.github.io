---
title: Weekly ML/DL News (7월 2주차)
date: 2020.07.04 12:00:00
categories:
- news
tags:
- ML
- DL
---


## 목차

- [Fast Speech2](#fast-speech2)
- [CoreML & Pytorch](#coreml--pytorch)
- [ReXNet](#rexnet)
- [Smooth Activation](#smooth-activation)
- [StarGAN v2](#stargan-v2)
- [Erase dead neuron](#erase-dead-neuron)
- [Transformers v3.0](#transformers-v30)
- [MIT 6.S191](#mit-6s191)
- [Colab tips](#colab-tips)


### Fast Speech2

[참고자료](https://tensorspeech.github.io/TensorflowTTS/)

MS의 FastSpeech2를 TensorFlowTTS가 지원하기 시작했다고 한다.

주장하기로는 Transformer 계열과 비슷한 성능이 나오면서도 학습시간은 2배이상, inference 시간은 150배 이상 빠르다고 하는데..

이 분야에 대해서 깊게 모르다보니 검증된 결과인가 싶기도하다. 시간되면 이 부분도 한번 테스트해보면 좋을듯.


### CoreML & Pytorch

[참고자료](https://github.com/apple/coremltools/releases/tag/4.0b1)

기존에 Pytorch로 작성된 모델을 CoreML로 포팅하려면 Pytorch -> ONNX -> CoreML 구조를 거쳤어야했는데, 이번 업데이트로
Pytorch -> CoreML이 가능해졌다고 한다.

아마 TorchScript처럼 불편한 점이 분명 존재하겠지만 차차 나아지지 않을까 생각됨. 이젠 Image Detection 같은 모델을 파이토치로 작성하고
손쉽게 모바일에 탑재해볼 수도 있을듯.


### ReXNet

[참고자료](https://github.com/clovaai/rexnet)

클로바에서 ReXNet이라는 모델을 공개했다. 나름 "경량화 이미지 백본의 야심작"이라는데 설명을 보면 EfficientNet보다 더 가벼운면서도 좋은 성능을
보여준다고 한다.

한번쯤 가져다 써봐도 좋을듯.


### Smooth Activation

[참고자료](https://arxiv.org/abs/2006.14536)

현 시대에 가장 널리 쓰이는 activation function인 ReLU 대신에 유사한 모양이지만 ELU나 GELU와 같은 smooth function을 사용하면
정확도가 유지되면서 보다 강건한 모델이 된다는 실험결과가 나왔다고 한다.

ReLU가 나오고 난 뒤 이 부분에 대한 연구는 크게 많이 나오지 않았던 것 같은데 구글&존스홉킨스 연구라 한번쯤 읽어보면 좋을듯.  


### StarGAN v2

[참고자료](https://github.com/clovaai/stargan-v2-tensorflow)

클로바에서 StarGAN v2 공식구현체를 공개했다. GAN에 관심있는 분들은 활용해보시길.


### Erase dead neuron

[참고자료](https://www.sciencealert.com/for-the-first-time-scientists-capture-video-of-brains-clearing-out-dead-neurons)

죽은 뉴런을 제거하는 뇌 영상을 최초로 얻었다고 한다. 중간의 뉴런이 죽으면 해당 뉴런을 제거하고 앞뒤를 연결해주는 별도 세포가 존재한다고 함.

뉴럴넷에서도 이런 컨셉을 적용해서 죽은 뉴런을 제거시켜버린다거나 그런게 가능하려나.. 생각해보면 좋을만한 주제인듯.


### Transformers v3.0

[참고자료](https://huggingface.co/transformers/index.html)

허깅페이스의 transformers가 버전 3.0이 나왔다. 허깅페이스는 다음과 같은 청사진을 그린다고하는데.

- NLP 연구자와 교육자들에게 큰 규모의 트랜스포머를 사용하고, 공부하고, 확장하게 하고
- 핸즈온 실용주의자들에게는 이 모델을을 fine-tune해서 제품에 서빙하게 하고
- 개발자들은 pre-trained된 모델을 사용해서 본인들의 문제를 풀수 있게 해준다

멋있는 이상을 가지고 일하는 조직인듯.


### MIT 6.S191

[참고자료](http://introtodeeplearning.com/)

MIT 딥러닝 기초강의 자료가 공개되었다.

정말 공부할게 수없이 쌓이고 있고, 새롭게 배우시는 분들은 그만큼 풍부한 자료로 공부하실 수 있을듯.

이제 자료가 없어서 공부를 못하는 시대는 지났으니 다들 열심히 공부를..


### Colab tips

[참고자료](https://amitness.com/2020/06/google-colaboratory-tips/)

구글 Colab을 좀 더 잘 활용할 수 있는 팁들을 정리해놓은 블로그.

당장 장비를 구축하지 않더라도 손쉽게 GPU를 활용한 모델링을 진행해볼 수 있다는 점에서 Colab은 정말 좋은 툴인듯.

.
