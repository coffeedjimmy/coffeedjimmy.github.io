---
layout: post
title: "Hive 똑똑하게 쓰기 01"
tags: [Hive, Hadoop, DevOps]
comments: true
---

- 하이브는 하둡 기반의 데이터 웨어하우징 프레임워크
- 하이브는 SQL 기술을 가진 분석가가 HDFS에 저장된 대량의 데이터를 분석할 수 있도록 하는 목적을 가지고 설계.

## 17.1. 하이브 설치하기
- Hive QL로 작성된 쿼리는 MR 잡으로 변환되어 하둡 클러스터에서 구동됨.
- Hive는 HDFS에 저장된 데이터(디렉터리/파일)에 구조(스키마)를 입히는 방식으로 데이터를 테이블로 구조화 시킴.
- 테이블 스키마와 같은 메타데이터는 metastore라고 불리는 데이터베이스에 저장.


### 17.1.1 Hive shell
- 하이브 쉘은 HiveQL로 하이브와 상호작용하는 하이브 기본 도구.
- HiveQL은 대소문자 구분 X

```bash
% hive -f script.hql  // f 옵션을 사용하여 파일에 대해 하이브 명령어 실행.
% hive -e 'SELECT * FROM dummy'  // e 옵션을 사용하여 명령행에 직접 입력.
% hive -S -e 'SELECT * FROM dummy'  // S 옵션을 이용해서 다른 부가적인 메세지가 아닌 쿼리의 결과만 확인 가능.
```


## 17.2 예제
- 크게 메모할 내용은 없음.
```bash
$ LOAD DATA LOCAL INPATH 'input/path/sample.txt' OVERWRITE INTO TABLE dummy;
```

- LOAD DATA의 OVERWRITE 키워드는 해당 테이블의 디렉터리에 존재하는 모든 파일을 삭제.
- OVERWRITE를 생략하면 새로운 파일은 단순히 그 테이블의 디렉터리에 추가되고, 같은 이름의 파일은 덮어씀.


## 17.3. Hive 실행하기


###17.3.1. 하이브 설정하기


- 하둡과 동일하게 XML 설정 파일을 사용하여 환결설정.
  - hive-site.xml → hive의 conf 디렉터리에 위치. 사용자가 하이브를 실행할 때마다 필요한 속성을 지정.
  - default.xml → conf 디렉터리에 위치하며 하이브가 보유하고 있는 속성과 기본값이 기록되어 있음.

```bash
% hive --config NEW_HIVE_CONF_PATH
```

- 위의 명령어를 통해 하이브가 hive-site.xml파일을 찾는 설정 디렉터리 재정의 가능.
- 단, 이 옵션은 hive-site.xml을 지정하는 것이 아니라 해당 디렉터리를 지정한다는 사실 주의.
- **HIVE_CONF_DIR** 환경변수 설정과 같은 효과

```bash
% hive -hiveconf fs.defaultFS=hdfs://localhost \
  -hiveconf mapreduce.framework.name=yarn \
  -hiveconf yarn.resourcemanager.address=localhost:8032
```

- -hiveconf를 사용해서 세션 기반의 속성을 설정할 수 잇음.

```bash
hive> SET hive.enforce.bucketing=true;
hive> SET hive.enforce.bucketing;
hive.enforce.bucketing=true
```

- 이런식으로 속성을 제어하는 경우 기본 설정을 재정의 하지 않는다면 기본 속성이 출력되지 않음 → 전체 속성을 다 보고싶으면  SET -v 을 사용하면 됨.
- 속성의 우선순위
  1. 하이브 SET 명령어
  2. 명령행 -hiveconf 옵션
  3. hive-site.xml과 하둡 site 파일 (core-site.xml, hdfs-site.xml 등)
  4. 하이브 기본 파일과 하둡 기본 파일 (core-default.xml, hdfs-default.xml 등)
- 기본적으로 하이브는 실행엔진으로 MR을 사용하도록 되어있지만, Tez라던가 스파크를 사용할 수도 있음.
  - 테즈와 스파크는 MR보다 더 성능이 좋고 유연성을 제공하는 DAG 엔진
  - MR은 기본적으로 임시 출력을 HDFS에 저장하지만, 테즈와 스파크는 임시 출력을 로컬디스크나 메모리에 저장하는 방식을 취하므로 복제 오버헤드를 피할 수 있음.

```bash
hive> SET hive.execution.engine=tez;
```

- 하이브이 에러로그 → ${java.io.tmpdir}/${user.name}/hive.log
- 로깅 설정 파일 → conf/hive=log4j.properties

```bash
% hive -hiveconf hive.root.logger=DEBUG,console  # 디버그 메세지를 콘솔로 보냄.
```

### 17.3.2 하이브 서비스
- 사실 하이브 쉘도 hive 명령어를 실행할 수 있는 여러 서비스 중 하나.
- 하이브 서비스 리스트
  - cli: 하이브 쉘에 대한 명령형 인터페이스
  - hiveserver2: 다른 언어로 개발된 클라이언트와 연동할 수 있도록 하이브를 Thrift 서비스로 실행
  - beeline: 일반적인 cli처럼 내장형 모드로 작동하거나 JDBC로 hiveserver2 프로세스에 접근할 수 있는 하이브의 명령행 인터페이스.
    - beeline은 두 가지 모드가 있는데 embedded mode/ remote mode가 있음.
      - Embedded mode - Hive CLI 와 유사하게 embeded hive 를 수행합니다. 로컬에 떠있는 hive에 접근한다고 보면 됨.
      - Remote mode - Thrift 통신을 통해 원격지에 있는 HiveServer2 에 접속하여 수행됩니다. 단, Thrift 통신만 허용합니다.
  - hwi: hive web interface. CLI의 대안으로 클라이언트 소프트웨어를 설치하지 않고, 하이브 접근가능. HUE가 그 예.
  - jar: hadoop jar와 상응하는 하이브 jar방식.
  - metastore: 기본적으로 메타스토어는 하이브 서비스와 동일한 프로세스에서 실행됨.
- 하이브 클라이언트
  - Thrift 클라이언트
  - JDBC 드라이버
  - ODBC 드라이버
