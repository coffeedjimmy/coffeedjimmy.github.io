---
title: Weekly ML/DL News (6월 4주차)
date: 2020.06.20 12:00:00
categories:
- news
tags:
- ML
- DL
---

이번 주에도 흥미로운 뉴스들이 많이 쌓였다. 페이스북에다만 쌓아두다가 정리를 하려고 하니
여간 귀찮은게 아니지만 나름 정리가 되어가고 있는듯 하여 뿌듯하다 ~~(고작 이주차)~~

## 목차

- [Andrej Karpathy](#andrej-karpathy)
- [Kaggle Online Workshop](#kaggle-online-workshop)
- [Huggingface notebooks](#huggingface-notebooks)
- [ImageGPT](#imagegpt)
- [Pytorch boilerplate](#pytorch-boilerplate)
- [Coursera NLP](#coursera-nlp)
- [BERT on CPU](#bert-on-cpu)
- [Jupyter Kernel for SQLite](#jupyter-kernel-for-sqlite)
- [CVPR20 Pytorch vs Tensorflow](#cvpr20-pytorch-vs-tensorflow)


### Andrej Karpathy

머신러닝에 관심있는 사람이라면 다들 아마 한번쯤 들어본 이름인 안드레이.

아마 논문읽는 것에 관심이 많은 분이라면 이 [사이트](arxiv-sanity.com)는 한번쯤 보셨으리라 생각한다. 그렇지만 아마 이 사이트를 만든 사람이 안드레이라는 건
생각보다 많은 사람들이 모를듯.

이런 안드레이가 [35세 이하 Innovator](https://www.technologyreview.com/innovator/andrej-karpathy/) 중 한명으로 선정되었다.

무려 아직 33세..

거기다가 최근에는 다음과 같은 포스팅을 남겼다.

![andrej's comment](/images/post_img/andrej.png)

1500편 가량의 논문을 스키밍해서 6시간만에 85편으로 좁혔다니.. 역시 대단한 사람인듯하다.


### Kaggle Online Workshop

[참고링크](https://www.kaggle.com/accelerator-power-hour?utm_medium=email&utm_source=gamma&utm_campaign=gm-workshop-email-1)

캐글 그랜드마스터들을 데리고 다음과 같은 주제를 가지고 Online workshop을 진행한다고 한다.

> Optimize your usage of GPUs and TPUs during this notebook based workshop for data science professionals

진행시간은 PDT 기준 6/25 오전 10시인데 우리나라 시간으로는 금요일 새벽 2시라 볼 수 있을까 걱정이긴 하다.


### Huggingface notebooks

[참고링크](https://huggingface.co/transformers/notebooks.html)

꽤나 예전부터 존재했던 자료인듯 하지만 생각보다 모르는 사람도 많은듯하고 정리가 잘 되어 있어서 다시 한번 포스팅.


### ImageGPT

[참고링크](https://openai.com/blog/image-gpt/)

현재 가장 핫한 모델 중 하나인 ImageGPT. 어쩌면 당연하게도 잘 동작하지 않을까하는 생각정도로 결과물을 봤는데 내 기대를 뛰어넘는 결과를 보였다.

물론 체리피킹이 없지는 않겠지만.. 충격적인 결과물인듯 하다. 이러한 결과물을 기계의 상상력이라고 표현하는 혹자도 있던데 그건 아직 난 잘 모르겠지만,
예술의 영역이 지속적으로 침범당할 수 있다는 생각이 들긴한다.

이정도 발전속도라면 인간이 편하고자 개발했지만 인간의 영역을 오히려 빼앗기는 사회가 오지 않을까.


### Pytorch boilerplate

[참고링크](http://research.sualab.com/development/2020/06/18/pytorch-boilerplate.html)

수아랩에 있으신 분들이 최근들어서 좋은 자료들을 많이 정리해주고 계신데, 이번에는 Pytorch기반의 실험환경구성에 대한 글을 작성해주셨다.

한번 읽어보고 우리 팀에도 적용해보면 좋지 않을까 생각.


### Coursera NLP

[참고링크](https://www.coursera.org/specializations/natural-language-processing)

앤드류 응 교수님이 설립한 deeplearning.ai에서 코세라에 NLP 코스를 새롭게 올렸다.

정말 이제 자료가 없어서 공부못했다는 건 핑계가 된 시대.. 이건 또 언제 볼지..


### BERT on CPU

[참고링크](https://medium.com/roblox-tech-blog/how-we-scaled-bert-to-serve-1-billion-daily-requests-on-cpus-d99be090db26)

BERT를 CPU 위에서 서빙하는데 있어서 어떤 실험들을 진행했는지 정리해놓은 포스팅.

Distillation, quantisation 등을 적용한 것으로 보이는데, 이 부분은 잘 정리해서 팀 내에 공유하면 좋을듯.


### Jupyter Kernel for SQLite

[참고자료](https://blog.jupyter.org/a-jupyter-kernel-for-sqlite-9549c5dcf551)

SQLite를 지원하는 Jupyter kernel이 나왔다는 내용.

이 부분도 한번쯤 테스트해보면 좋을듯.


### CVPR20 Pytorch vs Tensorflow

[참고자료](http://horace.io/pytorch-vs-tensorflow/)

위의 참고자료에 익숙하신 분들도 있을텐데, 사실 프레임워크의 선호에 대한 싸움?은 지속되어 왔다.

연구 쪽에서는 지속적으로 pytorch 선호가 있어왔었지만, TensorFlow의 뒤늦은 변화 (keras integration) 등으로 어떻게 변화할지 궁금했었다.

그런데 이번 결과는 다소 충격적인데 Pytorch가 TensorFlow 대비 4배나 더 많이 쓰였다.

이제 연구 쪽에선 거의 Pytorch의 압승이 아닌가 싶은데 또 생각해보면 왜 이렇게까지 차이가 벌어졌을까하는 궁금증이 들긴한다.

반대로 실제 서비스에서 사용되는 비율로 치면 어떻게 나올지도 궁금.

.
